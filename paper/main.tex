\documentclass[runningheads]{llncs}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}

\usepackage{amsmath,amssymb}
%\usepackage[square,numbers,sort&compress]{natbib}
\usepackage{xspace}
%% Useful packages
\usepackage{graphicx}
\usepackage{pdflscape,adjustbox}
\usepackage{multirow}
\usepackage{booktabs} % For formal tables
\usepackage{enumitem}
\usepackage{afterpage,tabularx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[square,numbers,sort]{natbib}
% Fixes for using natbib and llncs
\makeatletter
% required for natbib to have "References" printed and as section*, not chapter*
\renewcommand\bibsection%
{\section*{\refname\@mkboth{\MakeUppercase{\refname}}{\MakeUppercase{\refname}}}}
\renewcommand\@biblabel[1]{#1.}
\def\bibfont{\small}
\makeatother

% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
\renewcommand\UrlFont{\color{blue}\rmfamily}

\DeclareMathOperator*{\argmax}{arg\,max}

%% Revision documents
\usepackage[dvipsnames]{xcolor}
\usepackage[normalem]{ulem}
% FIXME: \sout is not very good. It cannot handle commands within its argument.
\newcommand{\SuggestEdit}[3][red]{\textcolor{#1}{\sout{#2}}\textcolor{#1}{#3}}
\let\svthefootnote\thefootnote
\newcommand\colorfootnote[2][black]{\def\thefootnote{\color{#1}\svthefootnote}%
  \footnote{\color{#1}#2}\def\thefootnote{\color{black}\svthefootnote}}
\newcommand\RevComment[3][red]{\protect\colorfootnote[#1]{{\textbf{[#2: #3]}}}}
% Command for edits, command for commenting and color
\newcommand\newrevisor[3]{%%
  \colorlet{#1}{#3}
  \expandafter\newcommand\csname#1\endcsname[2]{\SuggestEdit[#1]{##1}{##2}}%%
  \expandafter\newcommand\csname#2\endcsname[1]{\RevComment[#1]{#2}{##1}}%%
}
\newrevisor{manuel}{MANUEL}{Purple}

\hyphenation{%%% Merriam-Webster
  di-men-sion-al %%
  op-tical net-works semi-conduc-tor %%
  pher-o-mone non-dom-i-nance %%
  non-dom-i-nat-ed chro-mo-some %%
  sto-chas-tic make-span an-a-lys-ing}


\title{Mallows, Black-box combinatorial optimization, limited budget,  ???}
% Double-blind
\author{Double-blind}
% \author{Ekhiñe Irurozki\inst{1} \and Manuel López-Ibáñez\inst{2}\orcidID{0000-0001-9974-1295}}
% \institute{
%    Basque Center for Applied Mathematics\\
%    \email{eirurozki@bcamath.org}
%    \and
%    University of Málaga, Málaga, Spain\\
%    \email{manuel.lopez-ibanez@uma.es}
% }
\date{}%

\begin{document}

\maketitle

\begin{abstract}
%The abstract should briefly summarize the contents of the paper in
%150--250 words.
  Black-box combinatorial optimization problems arise in practice when the
  objective function is evaluated by means of a simulator or a real-world
  experiment. In such cases, classical techniques such as mixed-integer
  programming and local search cannot be applied. Moreover, often each solution
  evaluation is expensive in terms of time or resources, thus only a limited
  number of evaluations is possible, typically several order of magnitude
  smaller than in white-box optimization problems. In the continuous case,
  Bayesian optimization, in particular using Gaussian processes, has proven
  very effective under these conditions. Much less research is available in the
  combinatorial case. In this paper, we propose and analyze an
  estimation-of-distribution (EDA) algorithm based on a Mallows probabilistic
  model and compare it with CEGO, a Bayesian optimization algorithm for
  combinatorial optimization. Experimental results show that the Bayesian
  algorithm is able to obtain very good solutions with very few evaluations,
  however, at a significant computational cost, whereas the proposed EDA
  outperforms CEGO when the number of solutions evaluated approaches 400, and
  it is significantly faster. These results suggest that the combination of
  Bayesian optimization and a Mallows-based EDA may be an interesting direction
  for future research.
\textcolor{red}{16 pages max, deadline: 1 November 2020}
\keywords{Combinatorial optimization \and Bayesian optimization \and Expensive black-box optimization \and Estimation of distribution algorithms}
\end{abstract}

\section{Introduction}

Motivation: Manuel

In many practical optimization problems, the objective function is not
explicitly available and solutions are evaluated by means of expensive
prediction models, simulations or physical experiments. When decision variables
are continuous, the use of Bayesian surrogate-models, e.g., Gaussian processes,
in optimization has become
widespread~\citep{JonSchWel98go,ForKea2009surrogate}. Motivated by this
success, there have been attempts at adapting such Bayesian optimization
algorithms to the combinatorial case, a notable example being Combinatorial
Efficient Global Optimization
(CEGO)~\citep{ZaeStoBar2014:ppsn,ZaeStoFriFisNauBar2014}. However, the
ruggedness of combinatorial landscapes, which makes local search particularly
effective in the white-box context, lessens the effectiveness of global
surrogate models~\citep{EriPeaGar2019scalable}. Moreover, surrogate models are
expensive to train and optimize. The additional time required by the Bayesian
optimizer may impose a significant overhead in computation time, specially if
computation time of each function evaluation is measured in ``few'' minutes or
hours rather than days and when ``expensive'' refers to resources or economical
cost rather than wall-clock time. \citet{PerLopStu2015si} recently showed that
ant colony optimization (ACO)~\citep{DorStu2004:book} is competitive with CEGO
on a black-box version of the travelling salesman problem under a budget of
$1\,000$ function evaluations. ACO basically builds a probability distribution
model from which solutions are sampled with a bias towards the best solutions
evaluated so far. As such, ACO may be considered a type of
estimation-of-distribution algorithm (EDA) for combinatorial optimization. On
the other hand, $1\,000$ evaluations is a relatively large budget for CEGO and
ACO was not designed for such short budgets.

In this work, we propose and analyze uMM, an EDA specifically designed for
black-box combinatorial optimization under a limited budget. The proposed uMM \ldots\MANUEL{what is the inspiration}
\

% minimize the uncertainty in the final solutions or

Related work: Ekhine

Our contribution: Ekhine
\begin{itemize}
\item 
\end{itemize}


\citep{LopDubPerStuBir2016irace}

\section{Background}\label{sec:backgroud}

Permutations are defined as bijections of the set $[n]$ integer onto itself. The set of all permutations of $n$ items is denoted as $S_n$ and has cardinality $n!$. We denote permutations with Greek letters with exception of the inverse permutation denoted as $e=1, 2, 3, \ldots,n$. We denote the composition of $\sigma$ and $\pi$ as $\sigma\pi$ and the inverse of $\sigma$ as $\sigma^{-1}$, for which the relation $\sigma\sigma_{-1}=e$ always holds. 

Distributions over permutations are functions that assign a probability value to each of the permutations in $S_n$, $p(\sigma)\in[0,1]$ \cite{critchlow91}. One of the most popular distributions is the Mallows Model (MM), which is considered as an analogous to the Gaussian distribution for permutations. The MM defines the probability of each permutation $\sigma$ as follows:

\begin{equation}
p(\sigma)=\frac{\exp(-\theta d(\sigma, \sigma_0))}{\psi}
\end{equation}

with two parameters, $\theta$ and $\sigma_0$, 
where permutation $\sigma_0$ a reference permutation that has the largest probability value, i.e., the mode of the distribution. The probability of every permutation $\sigma\in S_n$ decays exponentially as its distance $d(\sigma,\sigma_0)$ increases, and $\theta$, the dispersion parameter controls this decay. The distance $d(\sigma,\sigma_0)$ is the Kendall's-$\tau$ distance. The normalization constant $\psi$ can be easily computed for the Kendall's-$\tau$ distance as well as for the Hamming, Cayley and Ulam distance~\cite{Irurozki2016b}. 

One of the most common problems related ti probability distributions is that of learning the maximum likelihood parameters  given a sample of data $S$. For the MM, this problem tranlates to learning $\theta$ and $\sigma_0$ that best describe a sample of permutations. 

The learning process is divide in two stages: first, we estimate the central permutation of the distribution, $\hat\sigma0$ and, second, compute the dispersion parameter, $\hat\theta$. 

The exact maximum likelihood estimation is computationally hard~\cite{Dwork:2001:RAM:371920.372165}. However, the approximate learning requires polynomilal computational time and is guarantied to obtain high quality parameters~\cite{Caragiannis2013,Coppersmith:2010}. 

This process of sample $S$ is as follows: first, compute $\hat\sigma0$ with the Borda count algorithm. Borda orders the items $[n]$ by their \textit{Borda score} increasingly, where the Borda score $B(i)$ is the average of each position $i$, $B(i) \propto \sum_{t\in S}  \sigma_t(i)$. Second, the computation of $\theta$ is casted as a numerical optimization problem~\cite{Irurozki2016b}. 

\subsection{Unbalanced Borda}\label{sec:uborda}
Recently, it has been proposed an extension of Borda by the name of uBorda. uBorda considers a sample of permutations $S$ along with a weight $w(\sigma)$ for each permutation $\sigma$~\cite{}. Intuitively it is equivalent to replicating the permutations in the sample proportionally to their weight. It has been used to learn a MM in an evolving preference context. In this paper, we propose to use uBorda where each permutation in the sample $\sigma\in S$ is weighted by its fitness function $w(\sigma)=f(\sigma)$.




LOP: Ekhine

Quizás luego: PFSP y QAP

\section{Methods}


\manuel{CEGO: Manuel.}{}

Combinatorial Efficient Global Optimization
(CEGO)~\citep{ZaeStoFriFisNauBar2014} is an extension of the well-known EGO
method~\citep{JonSchWel98go} to unconstrained black-box combinatorial
optimization problems. In EGO, Gaussian process models are used as a surrogate
of the landscape of the expensive original problem. An optimization method
searches for solutions in the surrogate model by optimizing the expected
improvement criterion, which balances the expected mean and variance of the
chosen solution. Once a solution is chosen, it is evaluated on the actual
objective function and the result is used to update the surrogate-model,
hopefully increasing its predictive power.

CEGO replaces the Euclidean distance measure, used by the surrogate model in
EGO, with a distance measure appropriate to combinatorial
landscapes~\citep{ZaeStoBar2014:ppsn}, such as the Kendall distance for
permutations~\citep{?}. In CEGO, the surrogate model is explored by a GA with
crossover and mutation operators appropriate for the particular combinatorial
problem. The original paper notes that coupling the GA with local search does
not improve the results significantly since the model is anyway an inexact
estimation of the original objective
function~\citep[p.~875]{ZaeStoFriFisNauBar2014}.

What else do we need to say?

\newcommand{\minit}{\ensuremath{m_\text{ini}}\xspace}

\newcommand{\FEmax}{\ensuremath{\textit{FE}_{\max}}}

cosas de intro : 
This new methodology relies on the assumption that the fitness landscatpe is correlated with a distribution over the same space. 
Previous paper have confirmed this point
For this case study, we show that this case for the Mallows model under the Kendall distance and 



In this section, we introduce our main contribution: We present a new methodology for the optimization of black box functions with a minimal number of queries. This methodology is a probabilistic, population-based algorithm. 

Essentially, the algorithm  considers a sample of permutations along with the fitness of each of them. It is an iterative process in which the number of iterations is fixed. 
Then, at each iteration, UMM (i) estimates a surrogate distribution of the fitness function and (ii) proposes a good fitted individual. 


\section{UMM }
In this section we describe our main contribution: a novel algorithm for the optimization of a black box function over permutation spaces. This algorithm is called Unbalanced Mallows model (UMM) since it a probabilistic method based on a well-known probability distribution for permutations: the Mallows model. 


The high-level behavior of UMM is as follows. It starts with an \textit{small} sample of $m'$ permutations that are randomly generated. UMM also keeps a probability distribution of a transformation of the sample. Then, for $m$ iterations, it generates a random, promising candidate solution and includes it in the sample. Each time a new permutation is included its fitness is computed and the internal probabilistic model is updated. 

The probabilistic model is a MM that assigns higher probability values to the permutations in which the fitness value is known or expected to be smaller.\footnote{We assume a minimization problem.} The main contribution of our approach is that the distribution does not represent the current sample considered by the algorithm but instead, represents a variation of it. This variation is abstractly equivalent to replicating in the sample the permutations inversely proportionally to their fitness values, i.e., there will be many copies of the good solutions and few of the bad ones. One key property of UMM is the computational complexity of working with the original sample and the transformed sample is the same, i.e., polynomial. However, the question os how many times should we replicate each permutation in the sample? UMM includes a parameter $\rho$ that controls this point and will be detailed in Section~\ref{sec:learning}

At each iteration of the algorithm the following steps take place: (1) randomly generate a permutation and include it in the sample and (2) evaluate the new permutation and update the probabilistic model. These steps correspond to two statistical operations: (1) sample a probability distribution and (2) learn a probability distribution of the transformation of the sample. Both are describe in the subsequent sections. 

\subsection{Learning step}\label{sec:learning}

As shown in Section~\ref{sec:backgroud}, MM can be approximately learnt in two steps (1) estimating the location parameter $\sigma_0$, usually done with Borda algorithm, and (2) computing the scale parameter $\theta$. Since the scale parameter is set automatically, we focus on learning the first step. 

%In order to minimize the number of permutations in the sample (and consequently the number of function evaluations) our proposed UMM learns the distribution of a transformation of the sample rather than the sample. This transformation consists on replicating the best fitted permutations. However, this is done abstractly: 
The location parameter can be shown to be the permutation in $S_n$ that minimizes the sum of the distances to the permutations in the sample~\cite{gMallows}, which is usually approximated with the Borda algorithm. Since we are interested on biasing the location towards the regions of the space where the fitness function is smaller, we would like to replicate the permutations a number of times that is inversely proportionally to their fitness values.
We can simulate the replication of the best fitted individuals by using uBorda, described in Section~\ref{sec:uborda} and setting $w(\sigma)=\rho^{f(\sigma)}$. This generalization requires setting a value for parameter $\rho$. We show how to choose this value in the experimental section. 


\subsection{Sampling step}
The Mallows model is defined by two parameters. The location $\sigma_0$ is the permutation with the largest probability value, and in our problem, the permutation that is supposed to be the global optimum. The scale parameter $\theta$ controls both the variance and the expected distance of a random permutation. Given these two parameters, sampling a MM has been studied in \cite{Collas}\cite{Irurozki2016b}\cite{Regenwetter2004} where the computational complexities are $O(n\log n)$ and $O(n^2)$.


At each iteration of UMM $\sigma_0$ is given by the permutation obtained as a solution in the previous learning step. The scale $\theta$, in the other hand, is set automatically by the algorithm to control the diversification and intensification trade off: At the first iteration it is set so that the expected distance equals  ${n\choose 4}$ (half of the distance of the uniform distribution), and then it linearly decrease until the last iteration where the expected distance equals 1. Similar approaches have been taken in different contexts~\cite{arza2019approaching}.

This setting reflects the fact that, despite believing that the best global optimum at each iteration is $\sigma_0$, the uncertainty at the fisrt stages of the algorithm is high and



\subsection{Comparison to standard probabilistic optimization approaches.}
UMM is a population based algorithm. There exists a wide body of research on population based probabilistic algorithms, where most prominent examples are Estimation of Distribution Algorithms (EDAs). Our approach drastically differs from EDAs since EDAs assume that function evaluations are cheap and they can do many of them. On the contrary, UMM minimizes the number of function evaluations. Moreover, UMM does not rely on an evolving sequence of samples (called generations in evolutionary approaches). Instead, UMM considers a single sample of permutations during the whole execution that is increased iteratively, with one permutation each iteration. 









\section{Experimental setup}

We use the implementation of GECO provided by the
authors\footnote{\url{https://cran.r-project.org/package=CEGO}}. Following the
authors of CEGO~\citep{ZaeStoFriFisNauBar2014,ZaeStoBar2014:ppsn}, we use and
the GA that optimizes the surrogate models uses a population size of 20,
crossover rate of 0.5, mutation rate of 1, tournament selection of size 2 and
probability of 0.9, interchange mutation (i.e., exchanging two randomly
selected elements of the permutation) and cycle crossover for permutations. The
authors of CEGO used a budget of $10^4$ evaluations using the surrogate-model
for each run of the GA, however, with such setting, each run of CEGO requires
more than a week of computation time, which was infeasible for us, hence, we
set a value of \textcolor{red}{$10^3$}.

Although it is never stated in the original paper, the implementation of CEGO
generates a set of initial solutions of size $\minit=10$ by means of a
max-min-distance sequential design: new solutions are added to the set
sequentially by maximizing the minimum distance to solutions already in the
set. These initial solutions are then evaluated on the actual objective
function and the result is used to build the initial surrogate
model.% \citet{ZaeStoBar2014:ppsn} uses 10

The CPU time required for a single run of CEGO using these settings is larger
than a week.  For simplicity, we use Kendall Tau distance~\citep{?} in all
experiments\MANUEL{\citet{ZaeStoBar2014:ppsn} claims this is called Swap
  distance, could you double-check?}. Nevertheless,
\citet{ZaeStoFriFisNauBar2014} points out that CEGO performs best on the QAP
when using Hamming distance. We plan to extend our analysis of uMM to other
distance measures and to the dynamic selection of distance
measures~\citep{ZaeStoBar2014:ppsn}.

In all experiments, we consider a maximum budget of $\FEmax=400$ evaluations of
the actual objective function. In a white-box context, state-of-the-art
algorithms for the problems considered here typically evaluate
\textcolor{red}{hundreds? thousands?} of solutions, thus, the budget considered
here for the black-box context is extremely limited.

We implemented UMM in Python 3. The parameter settings that we use are...

Complete this with details of uMM: MANUEL

\manuel{Computing system details: MANUEL}{%
  All experiments were run on Intel Xeon ``Ivybridge'' E5-2650v2 CPUs at 2.60\,GHz, 64\,GB RAM
  running CentOS Linux release 7.4.1708 (Core).  }


Describir como se generan las intancias de LOP: Ekhine

Describir las instancias: Ekhine

For the LOP, we generated synthetic instances of size $n=20$, $m=200$, $\phi\in\{0.5,0.7,0.9\}$\MANUEL{what is $m$?}

In the case of the QAP and PFSP, we consider the same instances as
\citet{ZaeStoFriFisNauBar2014,ZaeStoBar2014:ppsn}, i.e.,
\texttt{nug12},\texttt{nug30},\texttt{tho30} and \texttt{kra32} for the QAP,
with $n$ equal to the number in the instance name, and \texttt{reC05},
\texttt{reC13}, \texttt{reC19}, \texttt{reC31} for the PFSP, with
$n \in \{20, 20, 30, 50\}$, respectively.

\section{Experimental analysis}

Ekhine: How many runs do we do? 10 20? 10, cambio el texto

To better understand the behaviour of the algorithms, we record the fitness of
the solution evaluated at each step of each run and we average those values
over 10 runs on the same problem instances.  As an example, Fig.~\ref{fig:kra32} \textcolor{red}{por qué no mepezamos con la fig1?}
shows the mean fitness of the solutions evaluated by uMM and CEGO on one QAP
instance. The shaded area shows one standard deviation around the
mean. Ideally, each solution evaluated helps to refine the model and leads to a
better solution being evaluated in the next step.  However, the plot shows that \textcolor{red}{yo diría solo que lo esperable es que baje monotonically, sin entrar a valorar un ejemplo concreto}
the fitness of the solutions does not improve monotonically and new solutions
are often worse than their predecessors. Nevertheless, in this example, there
is a clear overall improvement as more evaluations are performed. The minimum
values achieved in the plot up to a particular number of function evaluations
gives an estimation of the mean fitness of the best-so-far solution up to that
point in the run. The algorithms do not return the final solution shown but
rather the best one (minimum fitness) of each run.


%: LOP syntéticas, todas en una gráfica. 
\begin{figure}
  \centering%
  \includegraphics[width=\textwidth]{img/synthetic_LOP_combined}
  \caption{Mean fitness  (and standard deviation)  of each solution evaluated by each algorithm on LOP synthetic instances.\label{fig:lop_synth}}
\end{figure}

When we compare the behaviour of CEGO and uMM on synthetic LOP instances
(Fig.~\ref{fig:lop_synth}), we observe a clear pattern independently of the
uniformity of the instances. In particular, CEGO starts with a random sampling
of X solutions, with are quite poor as expected, followed by building and
updating the Kriging model based new evaluations, which leads to an impressive
improvement in less than 50 evaluations. However, progress is more or less
halted at this point and the model seems to have trouble generating better
solutions. Lower uniformity values (e.g., $\mu=5$) show worsening evaluations
despite the increase in solutions used to build the model.

On the other hand, uMM converges much more slowly than CEGO, only reaching the
same fitness values around evaluation 250. Yet, uMM is able to keep the rate of
improvement and completely overtake CEGO around evaluation 350. As in the case
of CEGO, lower uniformity values lead to worse performance, although the
difference is much smaller for uMM than it was for CEGO.

In summary, the Kriging model clearly helps CEGO to quickly identify good
solutions in very few evaluations. However, for some reason, CEGO is not able to
further improve those solutions given more data. This may due to the
model not being able to produce accurate predictions or the underlying
optimizer not being able to find improved solutions using the model.\MANUEL{perhaps we should measure the prediction error and see if it grows or decreases. That would answer this question.}

\newcommand{\supplement}{\citep{Supplementary}}


%: LOP reales: he puesto 3 de diferentes tamanos. Me ha parecido interesante que, a pesar de que CEGO parece que va mejor, esta diferencia se va reduciendo segun se aumenta el tamano del problema (que se puede ver en el nombre del problema y en el títutlo de la gráfica)
\begin{figure}
  \centering%
  \includegraphics[width=\textwidth]{img/fitness_real_lop_RandA1_N-t1d100_01}\\
  \includegraphics[width=\textwidth]{img/fitness_real_lop_RandA1_N-t1d150_01}\\
  \includegraphics[width=\textwidth]{img/fitness_real_lop_RandA1_N-t1d200_01}\\
    \caption{Mean fitness  (and standard deviation)  of each solution evaluated by each algorithm on three instances from LOPLIB.\label{fig:loplib}}
  \end{figure}


The fast initial convergence of CEGO for synthetic LOP instances does not seem
to translate to the instances available in LOPLIB~\citep{}. We show in
Fig.~\ref{fig:loplib} three examples with different permutation size, however,
the results are consistent for other LOPLIB instances (complete results
available as supplementary material \supplement). Due to extremely long
runtimes of CEGO and constraints in our computing system, we set a maximum
wall-clock time of 5 days for each run of CEGO. On these instances, the
behaviour of CEGO and uMM is much more similar (at least up to the termination
point of CEGO). It appears that our synthetic LOP instances have a fitness
landscape that is very amenable to CEGO's Kriging model, whereas the LOPLIB
instances do not present such landscape. Comparing CEGO and uMM results, the
differences get smaller, in favour of uMM, with larger instance size. Our
conjecture is that building an accurate Bayesian model and searching for good
solutions on it becomes harder for larger fitness landscapes. 
\textcolor{red}{Parece que el paper va del CEGO en vez del UMM :p. Yo diría que tanto UMM como CEGO encuentran soluciones que mejoran según avanzan, pero con diferencias de comportamiento: (1) las los optimos de UMM son '3 veces mejor', y esto yo creo que es importante, aunque en gran parte se debe a que (2) UMM hace 400 ejecuciones en 3, 6 y 11 horas y CEGO entre 50 y 130 en 5 dias (3) cego empeora segun n aumenta (y n=200 tampoco es enorme)}

In the case of the PFSP, none of the algorithms are able to achieve a
  progress better than a random search would, as illustrated by the results
  (Fig.~\ref{fig:rec05}) obtained on \texttt{rec05}, which is the smallest PFSP
  instance considered here. The lack of any apparent convergence suggests that
  the models (both Bayesian and probabilistic) are not learning anything about
  the fitness landscape. Results for larger PFSP corroborate this conclusions
  (\supplement). Although previous studies~\citep{ZaeStoBar2014:ppsn} concluded
  that other distance measures are more suited than Kendall's-$\tau$ distance
  for the PFSP, the reported fitness differences between various distance
  metrics are small, hence, we conjecture that the same behaviour will be
  observed with other distance metrics.
  

\begin{figure}
  \centering%
  \includegraphics[width=\textwidth]{img/fitness_real_pfsp_rec05_txt}
  \caption{Mean fitness  (and standard deviation)  of each solution evaluated by each algorithm on the PFSP instance \texttt{rec05}.\label{fig:rec05}}
\end{figure}

The situation is very similar for the QAP, where both algorithms show the same
behaviour as in the PFSP for all instances tested, except for
\texttt{kra32}. As shown in Fig~\ref{fig:kra32}, in this instance both
algorithms are able to improve over the number of evaluations, although not
with ease. As in the synthetic LOP instances, we again observe that CEGO does
improve faster than UMM initially, yet, around evaluation 250, it appears to
get stuck and around evaluation 300, UMM overtakes it. We believe the reason is
the same as before, that is, the model is not able to adequately reflect the
ruggedness of the actual landscape and, hence, the best solutions found by the
GA searching the model are not improved solutions for the actual problem. Interestingly, \texttt{kra32} is rectangular
whereas \texttt{tho32} contains rectangular distances and \texttt{nug12} and \texttt{nug30} contain Manhattan distances of rectangular grids.\MANUEL{so they all have the same distance type!!!}

\begin{figure}
  \centering%
  \includegraphics[width=\textwidth]{img/fitness_real_qap_kra32_dat}
    \caption{Mean fitness  (and standard deviation)  of each solution evaluated by each algorithm on the QAP instance \texttt{kra32}.\label{fig:kra32}}
\end{figure}

In terms of best fitness achieved on each run, and taking into account the
random behaviour observed in some instances and discussed above,
Table~\ref{tab:results} shows\MANUEL{TODO}


%
%    \newcommand{\mcolc}[2]{\multicolumn{#1}{c}{\bf #2}}
%\begin{table}
%  \caption{Results.\label{tab:results}}
%  \resizebox{\textwidth}{!}{%
%\begin{tabular}{*{6}{r}c*{3}{r}}
%  \toprule
%            &                  & \mcolc{4}{Mean fitness (sd)} &                 & \mcolc{2}{Mean runtime}             & \bf     Mean FE\\\cmidrule{3-6}\cmidrule(lr){8-9}
%\bf Problem & \bf     Instance & \mcolc{2}{UMM}               & \mcolc{2}{CEGO} & \bf 95\% CI for the mean difference & \bf UMM  & \bf CEGO                                  & \bf CEGO           \\\midrule
%    LOP     & N-t1d100.01      & 76119.6                      & (915.4)         & 78696.6                             & (811.4)  & (1763.4904574743996, 3390.5095425256004)  & 11436.2 & 260954.5 & 111.8 \\
%    LOP     & N-t1d100.02      & 76827.7                      & (891.0)         & 79686.5                             & (367.9)  & (2194.5410893080507, 3523.058910691955)   & 11353.3 & 262421.6 & 110.7 \\
%    LOP     & N-t1d150.01      & 179508.3                     & (1647.9)        & 187605.5                            & (1906.9) & (6420.259663264915, 9774.140336735109)    & 23395.6 & 261712.4 & 73.9  \\
%    LOP     & N-t1d150.02      & 177592.8                     & (1196.2)        & 184320.9                            & (973.5)  & (5700.461476832616, 7755.738523167395)    & 23361.2 & 263389.9 & 74.1  \\
%    LOP     & N-t1d200.01      & 323513.6                     & (1371.2)        & 335391.1                            & (2289.0) & (10076.07401989604, 13678.92598010396)    & 38476.8 & 263467.5 & 55.6  \\
%    LOP     & N-t1d200.02      & 319675.8                     & (2242.6)        & 333149.5                            & (2497.2) & (11241.971680405779, 15705.428319594244)  & 38268.3 & 265217.5 & 56.5  \\
%    LOP     & N-t2d150.01      & 15297.7                      & (563.5)         & 24682.7                             & (976.6)  & (8622.206776092156, 10147.793223907844)   & 25318.6 & 262324.3 & 74.6  \\
%    LOP     & N-t2d150.02      & 14724.9                      & (667.5)         & 24250.8                             & (1354.9) & (8495.057408450935, 10556.742591549064)   & 25425.6 & 262079.2 & 74.8  \\
%    LOP     & N-t2d200.01      & 33465.2                      & (2001.0)        & 57098.6                             & (4452.8) & (20284.508914101127, 26982.291085898876)  & 40340.9 & 263908.9 & 56.3  \\
%    LOP     & N-t2d200.02      & 35901.8                      & (2077.5)        & 58123.0                             & (2334.9) & (9515.181030361815, 34927.21896963818)    & 40153.1 & 261723.6 & 55.0  \\\midrule
%   PFSP     & rec05            & 1330.7                       & (17.9)          & 1317.9                              & (25.1)   & (-33.424760001214985, 7.8247600012150755) & 506.1   & 139893.0 & 400.0 \\
%   PFSP     & rec13            & 2158.7                       & (29.5)          & 2128.2                              & (25.0)   & (-56.24362499249925, -4.756375007500754)  & 506.8   & 140167.2 & 400.0 \\
%   PFSP     & rec19            & 2405.1                       & (12.6)          & 2398.6                              & (19.8)   & (-22.313869704790818, 9.313869704790818)  & 1078.3  & 295442.7 & 400.0 \\\midrule
%    QAP     & kra32            & 116320.0                     & (4673.5)        & 115907.0                            & (4663.4) & (-4799.295389697205, 3973.295389697205)   & 1194.8  & 344766.2 & 400.0 \\
%    QAP     & nug12            & 660.4                        & (17.3)          & 624.2                               & (26.3)   & (-57.337505259978144, -15.06249474002172) & 180.0   & 53149.3  & 400.0 \\
%    QAP     & nug30            & 7474.0                       & (83.9)          & 7486.8                              & (40.4)   & (-50.84533806724974, 76.4453380672501)    & 1073.5  & 303352.6 & 400.0 \\
%    QAP     & tho30            & 191482.0                     & (4419.7)        & 192416.0                            & (2584.2) & (-2527.0213832396516, 4395.021383239651)  & 1066.5  & 306451.3 & 400.0 \\
%\bottomrule
%\end{tabular}}
%\end{table}

  \resizebox{\textwidth}{!}{
\begin{tabular}{lllllrrr}
\toprule
Problem &       Instance &           UMM fitness &           CEGO fitness &     Confidence interval &  UMM Runtime &  CEGO Runtime &  CEGO F. evaluations \\
\midrule
    LOP &    N-t1d100.01 &       76119.6 (915.4) &        78696.6 (811.4) &        (1763.5, 3390.5) &          3.2 &          72.5 &                111.8 \\
    LOP &    N-t1d100.02 &       76827.7 (891.0) &        79686.5 (367.9) &        (2194.5, 3523.1) &          3.2 &          72.9 &                110.7 \\
    LOP &    N-t1d150.01 &     179508.3 (1647.9) &      187605.5 (1906.9) &        (6420.3, 9774.1) &          6.5 &          72.7 &                 73.9 \\
    LOP &    N-t1d150.02 &     177592.8 (1196.2) &       184320.9 (973.5) &        (5700.5, 7755.7) &          6.5 &          73.2 &                 74.1 \\
    LOP &    N-t1d200.01 &     323513.6 (1371.2) &      335391.1 (2289.0) &      (10076.1, 13678.9) &         10.7 &          73.2 &                 55.6 \\
    LOP &    N-t1d200.02 &     319675.8 (2242.6) &      333149.5 (2497.2) &      (11242.0, 15705.4) &         10.6 &          73.7 &                 56.5 \\
    LOP &    N-t2d150.01 &       15297.7 (563.5) &        24682.7 (976.6) &       (8622.2, 10147.8) &          7.0 &          72.9 &                 74.6 \\
    LOP &    N-t2d150.02 &       14724.9 (667.5) &       24250.8 (1354.9) &       (8495.1, 10556.7) &          7.1 &          72.8 &                 74.8 \\
    LOP &    N-t2d200.01 &      33465.2 (2001.0) &       57098.6 (4452.8) &      (20284.5, 26982.3) &         11.2 &          73.3 &                 56.3 \\
    LOP &    N-t2d200.02 &      35901.8 (2077.5) &       54895.6 (4589.7) &      (15539.1, 22448.5) &         11.2 &          73.5 &                 55.6 \\
    LOP &       N-p50-01 &       21027.6 (711.8) &        21431.2 (299.5) &         (-128.1, 935.3) &          0.9 &          72.3 &                219.9 \\
    LOP &       N-p50-02 &       21613.6 (596.4) &        22021.1 (275.6) &          (-42.5, 857.5) &          0.9 &          72.3 &                217.3 \\
    LOP &       N-atp111 &          594.0 (15.4) &           693.1 (10.3) &           (86.7, 111.5) &          4.1 &          72.5 &                 98.7 \\
    LOP &       N-atp134 &          756.3 (21.3) &           880.5 (18.6) &          (105.4, 143.0) &          5.7 &          72.8 &                 83.0 \\
    LOP &  N-be75eec\_150 &   1415208.5 (58593.5) &    1666193.1 (72310.8) &    (188960.6, 313008.6) &          6.9 &          72.9 &                 74.0 \\
    LOP &  N-be75eec\_250 &  4431271.0 (109756.7) &   5214413.0 (166701.4) &    (649040.8, 917243.2) &         15.5 &          73.7 &                 44.9 \\
    LOP &   N-be75np\_150 &   3204878.3 (80704.1) &    3742444.0 (88500.2) &    (457944.2, 617187.2) &          6.9 &          72.9 &                 74.2 \\
    LOP &   N-be75np\_250 &  9544754.9 (260523.9) &  10887427.8 (159642.5) &  (1136635.8, 1548710.0) &         15.5 &          74.0 &                 45.3 \\
   PFSP &      rec05.txt &         1330.7 (17.9) &          1317.9 (25.1) &            (-33.4, 7.8) &          0.1 &          38.9 &                400.0 \\
   PFSP &      rec13.txt &         2158.7 (29.5) &          2128.2 (25.0) &           (-56.2, -4.8) &          0.1 &          38.9 &                400.0 \\
   PFSP &      rec19.txt &         2405.1 (12.6) &          2398.6 (19.8) &            (-22.3, 9.3) &          0.3 &          82.1 &                400.0 \\
    QAP &      kra32.dat &     116320.0 (4673.5) &      115907.0 (4663.4) &       (-4799.3, 3973.3) &          0.3 &          95.8 &                400.0 \\
    QAP &      nug12.dat &          660.4 (17.3) &           624.2 (26.3) &          (-57.3, -15.1) &          0.0 &          14.8 &                400.0 \\
    QAP &      nug30.dat &         7474.0 (83.9) &          7486.8 (40.4) &           (-50.8, 76.4) &          0.3 &          84.3 &                400.0 \\
    QAP &      tho30.dat &     191482.0 (4419.7) &      192416.0 (2584.2) &       (-2527.0, 4395.0) &          0.3 &          85.1 &                400.0 \\
\bottomrule
\end{tabular}}





\section{Conclusions}

Bayesian optimization methods using a global GP model, such as CEGO, are known
to have trouble optimizing locally \citep{EriPeaGar2019scalable}. Our
intuition is that this problem becomes worse in rugged combinatorial
landscapes, where small steps may produce drastic changes.

Open questions:
\begin{itemize}
\item How difficult is to extend uMM to other distance metrics?
\item Can we plot the posterior probability of the optimal solution?
\end{itemize}

\paragraph*{Acknowledgements.}

Thanks to Hao Wang (Leiden University) for pointing us to the arguments of
\citet{EriPeaGar2019scalable}.




\renewcommand{\doi}[1]{doi:\hspace{.16667em plus .08333em}\discretionary{}{}{}\href{https://doi.org/#1}{\urlstyle{rm}\nolinkurl{#1}}}
\bibliographystyle{splncs04nat}
\bibliography{optbib/abbrev,optbib/authors,optbib/journals,optbib/biblio,optbib/crossref,./mendeley}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
